2019-03-23 11:11:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 12, in parse
    dailis = response.xpath("//tr[@class='odd']") + response.xpath("//tr[@class=''")
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //tr[@class=''
2019-03-23 11:11:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 12, in parse
    dailis = response.xpath("//tr[@class='odd']") + response.xpath("//tr[@class=''")
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //tr[@class=''
2019-03-23 11:11:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 12, in parse
    dailis = response.xpath("//tr[@class='odd']") + response.xpath("//tr[@class=''")
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //tr[@class=''
2019-03-23 11:11:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 13, in parse
    daili_2 =  + response.xpath("//tr[@class=''")
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //tr[@class=''
2019-03-23 11:12:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 13, in parse
    daili_2 =  + response.xpath("//tr[@class=''")
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //tr[@class=''
2019-03-23 11:12:54 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 13, in parse
    daili_2 =  + response.xpath("//tr[@class=''")
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //tr[@class=''
2019-03-23 11:13:10 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 13, in parse
    daili_2 = response.xpath("//tr[@class=''")
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //tr[@class=''
2019-03-23 11:13:40 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 15, in parse
    print(len(daili_1), "daili:")
NameError: name 'daili_1' is not defined
2019-03-23 11:13:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 15, in parse
    print(len(daili_1), "daili:")
NameError: name 'daili_1' is not defined
2019-03-23 11:14:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 13, in parse
    daili_2 = response.xpath("//tr[@class=''")
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //tr[@class=''
2019-03-23 11:14:24 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 13, in parse
    daili_2 = response.xpath("//tr[@class=''")
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //tr[@class=''
2019-03-23 11:14:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 14, in parse
    daili_2 = response.xpath("//tr[@class=''")
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //tr[@class=''
2019-03-23 11:15:12 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 14, in parse
    daili_2 = response.xpath("//tr[@class=''")
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //tr[@class=''
2019-03-23 11:15:25 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
lxml.etree.XPathEvalError: Invalid predicate

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 14, in parse
    daili_2 = response.xpath("//tr[@class=''")
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\http\response\text.py", line 119, in xpath
    return self.selector.xpath(query, **kwargs)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 242, in xpath
    six.reraise(ValueError, ValueError(msg), sys.exc_info()[2])
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\six.py", line 692, in reraise
    raise value.with_traceback(tb)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\parsel\selector.py", line 238, in xpath
    **kwargs)
  File "src/lxml/etree.pyx", line 1586, in lxml.etree._Element.xpath
  File "src/lxml/xpath.pxi", line 307, in lxml.etree.XPathElementEvaluator.__call__
  File "src/lxml/xpath.pxi", line 227, in lxml.etree._XPathEvaluatorBase._handle_result
ValueError: XPath error: Invalid predicate in //tr[@class=''
2019-03-23 11:19:36 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 22, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:20:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 22, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:20:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 22, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:23:06 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 22, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:24:55 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:24:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 23, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:24:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x0000016DA8C441D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:56 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:25:57 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 23, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:25:57 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x0000018E04731128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:26:51 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 23, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:26:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x00000190550041D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.item_scraped of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 220, in item_scraped
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:27:41 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 24, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:27:41 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x00000202AB684128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:28:20 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x00000269FBAB5160>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:28:21 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x00000269FBAB5160>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:29:05 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x0000023233944128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:29:06 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x0000023233944128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:29:25 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x000001E0050540F0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:29:25 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x000001E0050540F0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:29:58 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x0000022C34693240>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:29:58 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x0000022C34693240>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:32:13 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x00000198E7DB9128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:32:14 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 26, in parse
    item["severaddr"] = t= daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:32:14 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x00000198E7DB9128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:32:44 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x000001D912C56128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:32:45 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 26, in parse
    item["severaddr"] = t= daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:32:45 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x000001D912C56128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:32:58 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x000001CDE36A4128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:32:59 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x000001CDE36A4128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:34:24 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x00000213444CD240>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:34:25 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x00000213444CD240>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:34:51 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x0000026AA96641D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:34:52 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 26, in parse
    item["severaddr"] = t= daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:34:52 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x0000026AA96641D0>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:35:04 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.open_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x00000212D2F14128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 192, in open_spider
    file = storage.open(spider)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 88, in open
    return open(self.path, 'ab')
PermissionError: [Errno 13] Permission denied: 'xicidailis.csv'
2019-03-23 11:35:05 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 654, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 26, in parse
    item["severaddr"] = t= daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:35:05 [scrapy.utils.signal] ERROR: Error caught on signal handler: <bound method FeedExporter.close_spider of <scrapy.extensions.feedexport.FeedExporter object at 0x00000212D2F14128>>
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\twisted\internet\defer.py", line 151, in maybeDeferred
    result = f(*args, **kw)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\pydispatch\robustapply.py", line 55, in robustApply
    return receiver(*arguments, **named)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\extensions\feedexport.py", line 201, in close_spider
    slot = self.slot
AttributeError: 'FeedExporter' object has no attribute 'slot'
2019-03-23 11:35:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 26, in parse
    item["severaddr"] = t= daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:36:02 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 26, in parse
    item["severaddr"] = t= daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:41:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 20, in parse
    item["severaddr"] = t= daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:42:53 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 21, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:43:11 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 21, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:43:37 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 21, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:43:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 21, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:45:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 21, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:45:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 21, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:45:59 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 21, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:46:56 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 21, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 11:50:35 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.xicidaili.com/> (referer: None)
Traceback (most recent call last):
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 30, in process_spider_output
    for x in result:
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Anaconda3\envs\spider_scrapy\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "G:\Git_Repository\spider\习题班\scrapy_spider\xicidaili\xicidaili\spiders\Xicidaili.py", line 21, in parse
    item["severaddr"] = daili.xpath("./td[4]/text()").extract()[0]
IndexError: list index out of range
2019-03-23 16:46:58 [twisted] CRITICAL: Unhandled error in Deferred:
2019-03-23 16:46:58 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "G:\Anaconda3\lib\site-packages\scrapy\utils\misc.py", line 47, in load_object
    obj = getattr(mod, name)
AttributeError: module 'scrapy_spider.xicidaili.xicidaili.DaiLI_pipeline' has no attribute 'DaiLi_to_sql_pipeline'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "G:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "G:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "G:\Anaconda3\lib\site-packages\scrapy\utils\misc.py", line 49, in load_object
    raise NameError("Module '%s' doesn't define any object named '%s'" % (module, name))
NameError: Module 'scrapy_spider.xicidaili.xicidaili.DaiLI_pipeline' doesn't define any object named 'DaiLi_to_sql_pipeline'
2019-03-23 17:12:01 [twisted] CRITICAL: Unhandled error in Deferred:
2019-03-23 17:12:01 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "G:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "G:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: Daili_pipeline() missing 1 required positional argument: 'object'
2019-03-23 17:13:35 [twisted] CRITICAL: Unhandled error in Deferred:
2019-03-23 17:13:35 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "G:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "G:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: Daili_pipeline() missing 1 required positional argument: 'object'
2019-03-23 17:14:41 [twisted] CRITICAL: Unhandled error in Deferred:
2019-03-23 17:14:41 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "G:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "G:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: Daili_pipeline() missing 1 required positional argument: 'object'
2019-03-23 17:15:57 [twisted] CRITICAL: Unhandled error in Deferred:
2019-03-23 17:15:57 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "G:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "G:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: Daili_pipeline() missing 1 required positional argument: 'object'
2019-03-23 17:16:58 [twisted] CRITICAL: Unhandled error in Deferred:
2019-03-23 17:16:58 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "G:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "G:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: Daili_pipeline() missing 1 required positional argument: 'object'
2019-03-23 17:18:42 [twisted] CRITICAL: Unhandled error in Deferred:
2019-03-23 17:18:42 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "G:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "G:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: Daili_pipeline() missing 1 required positional argument: 'object'
2019-03-23 17:21:42 [twisted] CRITICAL: Unhandled error in Deferred:
2019-03-23 17:21:42 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "G:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "G:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: Daili_pipeline() missing 1 required positional argument: 'object'
2019-03-23 17:26:11 [twisted] CRITICAL: Unhandled error in Deferred:
2019-03-23 17:26:11 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "G:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "G:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: Daili_pipeline() missing 1 required positional argument: 'object'
2019-03-23 17:26:55 [twisted] CRITICAL: Unhandled error in Deferred:
2019-03-23 17:26:55 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "G:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "G:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: Daili_pipeline() missing 1 required positional argument: 'object'
2019-03-23 17:28:04 [twisted] CRITICAL: Unhandled error in Deferred:
2019-03-23 17:28:04 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "G:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 80, in crawl
    self.engine = self._create_engine()
  File "G:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 105, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "G:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 58, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "G:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 40, in from_settings
    mw = mwcls()
TypeError: Daili_pipeline() missing 1 required positional argument: 'object'
